from pathlib import Path

import pandas as pd
import spikeinterface.extractors as se

from . import select


def get_sorting_info(ks_dir):
    # Read params.py
    d = {}
    with open(ks_dir / "params.py") as f:
        for line in f.readlines():
            (key, val) = line.rstrip("\n").split(" = ")
            d[key] = val
    d["sample_rate"] = float(d["sample_rate"])
    d["n_channels_dat"] = int(d["n_channels_dat"])
    d["dtype"] = str(d["dtype"].strip("'"))
    d["hp_filtered"] = bool(d["hp_filtered"])
    # duration
    tmp_extr = se.BinaryRecordingExtractor(
        file_paths=ks_dir / "temp_wh.dat",
        sampling_frequency=d["sample_rate"],
        num_chan=d["n_channels_dat"],
        dtype=d["dtype"],
    )
    d["duration"] = tmp_extr.get_num_frames() / tmp_extr.get_sampling_frequency()
    return d


# TODO: Should this run automatically as part of the quality metrics pipeline?
# TODO: Remove and refactor. This function should no longer be necessary, since the (BasePhy)KilosortSortingExtractor loads cluster_info.tsv?
# cluster_info properties can be accessed via extr.get_property(col_name)
# What this function really seems to do is check whether parts of the pipeline has been completed:
# This function is really a check for whether or not cluster_info.tsv needs to be generated by Phy, which should be its own function.
# This function also checks whether metrics.csv was incorporated into cluster_info.tsv, which should also be its own function.


def get_cluster_info(ks_dir):
    """Load `cluster_info.tsv` generated by phy."""
    # Load cluster info
    cluster_info_path = ks_dir / "cluster_info.tsv"
    if not cluster_info_path.exists():
        import warnings

        warnings.warn("No `cluster_info.tsv` file in ks dir. Generating it using phy.")
        create_phy_cluster_info(ks_dir)
    info = pd.read_csv(cluster_info_path, sep="\t")
    # Make sure we loaded the metrics.csv
    if (ks_dir / "metrics.csv").exists() and not any(
        ["isi_viol" in c for c in info.columns]
    ):  # Check that one of the cols is "isi_viol*"
        import warnings

        warnings.warn(
            "Regenerate `cluster_info.tsv` file in ks dir to include metrics.csv."
        )
        create_phy_cluster_info(ks_dir)
        info = pd.read_csv(cluster_info_path, sep="\t")
    return info


# TODO: Phy imports are inside the function to avoid making phy a project dependency.
def create_phy_cluster_info(ks_dir):
    """Create `cluster_info.tsv` in kilosort dir.

    Same effect as running `phy template-gui <ks_dir>/params.py` and hitting save
    in the GUI."""
    raise NotImplementedError(
        f"Please create cluster_info.tsv file manuallt for {ks_dir} "
        "by opening Phy and clicking 'save'"
    )
    # from phy.apps.template import TemplateController
    # from phylib.io.model import load_model

    # model = load_model(Path(ks_dir) / "params.py")
    # controller = TemplateController(dir_path=ks_dir, model=model)
    # controller._save_cluster_info()


def get_cluster_groups(ks_dir, cluster_group_overrides=None):
    """Load cluster group as (nclust, 0) np array.

    Use KSLabel assignment when curated `group` is None or 'unscored'.

    Kwargs:
        cluster_group_overrides (None or dict): Dictionary of {<group>: <cluster_list>} used to
            override the groups saved in phy.
    """
    info = get_cluster_info(ks_dir)
    return select._get_cluster_groups(
        info["group"],
        info["cluster_id"],
        cluster_group_overrides=cluster_group_overrides,
    )


# TODO: This doesn't really return an extractor anymore, but rather a sorting?
# TODO: This doesn't really need to be a function.
def load_sorting_extractor(
    ks_dir,
    selected_groups=None,
    good_only=False,
    drop_noise=True,
    selection_intervals=None,
    cluster_group_overrides=None,
):
    """
    Return spikeinterface subextractor object. Subset clusters of interest.

    Args:
        ks_dir (str or pathlib.Path): Kilosort directory

    Kwargs:
        selected_groups (list or None): List of subselected cluster groups. Affected by `drop_noise` and `good_only` overrides.
        good_only (bool): Subselect `cluster_group == 'good'`.
            We use KSLabel assignment when curated `group` is None or 'unscored'
        drop_noise (bool): Subselect `cluster_group != 'noise'`
        selection_intervals (None or dict): Dictionary of {<col_name>: (<value_min>, <value_max>)} used
            to subset clusters based on depth, firing rate, metrics value, etc
            All keys should be columns of `cluster_info.tsv` or `metrics.csv`, and the values should be numrical.
        cluster_group_overrides (None or dict): Dictionary of {<group>: <cluster_list>} used to
            override the groups saved in phy.
    """
    # Extractor
    extr = se.KiloSortSortingExtractor(ks_dir)
    print(f"N clusters (all)={len(extr.get_unit_ids())}")
    return select.subset_clusters(
        extr,
        get_cluster_info(ks_dir),
        selected_groups=selected_groups,
        good_only=good_only,
        drop_noise=drop_noise,
        selection_intervals=selection_intervals,
        cluster_group_overrides=cluster_group_overrides,
    )
